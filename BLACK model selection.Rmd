---
title: "Black/Asian carp model selection"
author: "Eddie Wu"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This .Rmd file is to show the progress on black carp and asian carp temperature and condition analyses. Since sub-sampling from spatial autocorrelation does not give significantly different results from normal analysis for black carp, we present the results without sub-sampling here. For other asian carp species, we still subsample.

For each species, we have four different models:

1.  Simple linear model (same slope, same intercept)
2.  Linear additive model (same slope, different intercept)
3.  Interaction model (different slope, same intercept)
4.  Group-specific model (different slope, different intercept)

And we consider two temperature metrics:

1.  Annual temperature
2.  Winter temperature (temperature from the coldest quarter)

```{r data import, message=FALSE, warning=FALSE}
library(ggplot2)
library(ggfortify)
library(dplyr)
library(knitr)
library(tidyverse)
library(AICcmodavg) # for AICc and akaike weights
library(pwr)

## Import data
asian.carp <- read.csv("asian carp final.csv")
asian.carp$Condition <- as.factor(asian.carp$Condition)

Black <- read.csv("eddie_carp_new.csv")
Black$condition <- as.factor(Black$condition)

## Separate by species
Grass <- asian.carp[asian.carp$Species=="Grass",]
Bighead <- asian.carp[asian.carp$Species=="Bighead",]
Silver <- asian.carp[asian.carp$Species=="Silver",]
Big.sil <- rbind(Bighead, Silver) # combine the two groups


## Define two functions for AICs
compute_akaike_weights <- function(aic_scores) {
  # Find the AIC of the best model
  aic_min <- min(aic_scores)
  
  # Calculate delta AIC values
  d_aic <- aic_scores - aic_min
  
  # Compute Akaike weights
  akaike_weights <- exp(-0.5 * d_aic) / sum(exp(-0.5 * d_aic))
  
  return(akaike_weights)
}
compare_aic_scores <- function(aic_scores) {
  # Find the AIC of the best model
  aic_min <- min(aic_scores)
  
  # Determining if the smallest value is 2 units smaller than the others
  is_smaller_by_two <- all(aic_min + 2 <= aic_scores[aic_scores != aic_min])
  
  # Return the index if 
  if (is_smaller_by_two) {
    min_index <- which(aic_scores == aic_min)
    return(min_index)
  } else {
    return(-999)
  }
}
```

## Black carp

For black carp data, we do not subsample at any distances. But we removed the South Ukarine data point for all the following analyses.


### Temperature prediction of black carp AAM

```{r temperature prediction}
# Clean data
Black <- Black %>% filter(!row_number() == 5) %>% filter(sex != "male")

# Remove the South Ukarine data point
black.clean <- Black %>% filter(!row_number() == 20)

## Build the models with three temperature metrics
black.annual <- lm(log(AAM)~AnnualTemp, data = black.clean)
black.cold <- lm(log(AAM)~ColdTemp, data = black.clean)
black.warm <- lm(log(AAM)~WarmTemp, data = black.clean)

summary(black.annual)
summary(black.cold)
summary(black.warm)


## Power analyses - annual
# calculate the coefficient of determination
coe.annual <- summary(black.annual)$adj.r.squared
pwr.f2.test(u = 1, v = 22 - 1 - 1, f2 = coe.annual/(1 -coe.annual),
            sig.level = 0.05)

## Power analyses - annual
# calculate the coefficient of determination
coe.cold <- summary(black.cold)$adj.r.squared
pwr.f2.test(u = 1, v = 22 - 1 - 1, f2 = coe.cold/(1 -coe.cold),
            sig.level = 0.05)
pwr.f2.test(u = 1, f2 = coe.cold/(1 -coe.cold),
            sig.level = 0.05, power = 0.8)
```

* We can see that annual temperature and cold temperature are significant predictors of black carp AAM. Warm temperature is not.

* Power analyses suggested that our current sample size is sufficient enought to produce a strong statistical power.


### Model selection using annual temperature - no subsample

```{r black carp annual temp}
# Build the models
black.simple <- lm(log(AAM)~AnnualTemp, data = black.clean)
black.linear <- lm(log(AAM)~AnnualTemp+condition, data = black.clean)
black.int <- lm(log(AAM)~AnnualTemp:condition, data = black.clean)
black.group <- lm(log(AAM)~AnnualTemp*condition, data = black.clean)


## Compare the AICs
AIC(black.simple, black.linear, black.int, black.group)

# Get a table of corrected AICs and their Akaike weights
models <- list(black.simple, black.linear, black.int, black.group)
mod.names <- c('simple linear', 'linear additive',
               'interaction', "grouped-specific")
aictab(cand.set = models, modnames = mod.names, sort = FALSE)


# R^2 value for the four models
r_2 <- data.frame(
  Model = c("Simple linear", "Linear additive", "Interaction", "Grouped"),
  R2 = c(summary(black.simple)$adj.r.squared,
         summary(black.linear)$adj.r.squared,
         summary(black.int)$adj.r.squared,
         summary(black.group)$adj.r.squared)
)
kable(r_2)


## Look at the summary (especially the slope for each model)
summary(black.simple)
summary(black.linear)
summary(black.int)
summary(black.group)
```

### Model selection using cold temperature - no subsample

```{r black carp cold temp}
# Build the models
black.simple <- lm(log(AAM)~ColdTemp, data = black.clean)
black.linear <- lm(log(AAM)~ColdTemp+condition, data = black.clean)
black.int <- lm(log(AAM)~ColdTemp:condition, data = black.clean)
black.group <- lm(log(AAM)~ColdTemp*condition, data = black.clean)


# Compare the AICs
AIC(black.simple, black.linear, black.int, black.group)

# Get a table of corrected AICs and their Akaike weights
models <- list(black.simple, black.linear, black.int, black.group)
mod.names <- c('simple linear', 'linear additive',
               'interaction', "grouped-specific")
aictab(cand.set = models, modnames = mod.names, sort = FALSE)


## R^2 value for the four models
r_2 <- data.frame(
  Model = c("Simple linear", "Linear additive", "Interaction", "Grouped"),
  R2 = c(summary(black.simple)$adj.r.squared,
         summary(black.linear)$adj.r.squared,
         summary(black.int)$adj.r.squared,
         summary(black.group)$adj.r.squared)
)
kable(r_2)


## Look at the summary (especially the slope for each model)
summary(black.simple)
summary(black.linear)
summary(black.int)
summary(black.group)
```

* No significant preference among the four models. Therefore, the simple linear model is selected.

* Cold temperature in general gives better predictions (lower AICc and higher R2).


### Black carp graphs with two conditions separated

We separated the black carp dataset into two based on conditions. Since there was no preference over the four models, we used the simple linear model on each set of the data.

```{r black carp graphs}
## Annual temperature
ggplot(black.clean, aes(x = AnnualTemp, y = log(AAM), color = condition))+
  geom_point()+
  geom_smooth(method = "lm")+
  theme_bw()+
  labs(title = "Mean annual Temperature")


## Cold temperature
ggplot(black.clean, aes(x = ColdTemp, y = log(AAM), color = condition))+
  geom_point()+
  geom_smooth(method = "lm")+
  theme_bw()+
  labs(title = "Cold Quarter Temperature")
```

Now that we have seen that the artificial condition data seems to have a larger spread, we would like to run the simple linear model to take a look.

```{r blak carp conditions}
## Separate into two data sets
black.natural <- black.clean[black.clean$condition == "natural",]
black.artificial <- black.clean[black.clean$condition == "artificial",]


## Run the models
black.annual.n <- lm(log(AAM)~AnnualTemp, data = black.natural)
black.cold.n <- lm(log(AAM)~ColdTemp, data = black.natural)

black.annual.a <- lm(log(AAM)~AnnualTemp, data = black.artificial)
black.cold.a <- lm(log(AAM)~ColdTemp, data = black.artificial)


## Compare the AIC scores
AIC(black.annual.n, black.annual.a) #for annual temperature
AIC(black.cold.n, black.cold.a) #for cold temperature


## Compare the model parameters
summary(black.annual.n)
summary(black.annual.a)
summary(black.cold.n)
summary(black.cold.a)
```

* It turned put that after separating out the artificial condition, the model performed much better. While the artificial model alone did not even have a significant relationship.


## Asian carp

### Define the models and check the R2

```{r asian carp model}
## Look at the spatial codes for the current asian carp data
asian.carp.clean <- asian.carp %>% 
  filter(Condition %in% c("natural", "artificial"))

table(asian.carp.clean$Code)


## Subsampling for 1000 times (define all four models in one iteration!)
# Create the matrices to store the results
asian.linear.results <- matrix(NA,1000,4)
asian.add.results <- matrix(NA,1000,4)
asian.int.results <- matrix(NA,1000,4)
asian.group.results <- matrix(NA,1000,4)

# Slopes for all models


# Iteration (put both annual and cold inside one iteration)
for(i in 1:1000){
  sub <- asian.carp.clean %>% group_by(Code) %>% sample_n(size=1)
  
  # annual
  reg.linear.annual <- lm(log(AAM)~AnnualTemp, data = sub)
  reg.add.annual <- lm(log(AAM)~AnnualTemp+Condition, data = sub)
  reg.int.annual <- lm(log(AAM)~AnnualTemp:Condition, data = sub)
  reg.group.annual <- lm(log(AAM)~AnnualTemp*Condition, data = sub)
  
  # AICs for annual
  asian.linear.results[i,1]<-as.numeric(AICc(reg.linear.annual))
  asian.add.results[i,1]<-as.numeric(AICc(reg.add.annual))
  asian.int.results[i,1]<-as.numeric(AICc(reg.int.annual))
  asian.group.results[i,1]<-as.numeric(AICc(reg.group.annual))
  
  # R2 for annual
  asian.linear.results[i,2]<-summary(reg.linear.annual)$adj.r.squared
  asian.add.results[i,2]<-summary(reg.add.annual)$adj.r.squared
  asian.int.results[i,2]<-summary(reg.int.annual)$adj.r.squared
  asian.group.results[i,2]<-summary(reg.group.annual)$adj.r.squared
  
  # cold
  reg.linear.cold <- lm(log(AAM)~ColdTemp, data = sub)
  reg.add.cold <- lm(log(AAM)~ColdTemp+Condition, data = sub)
  reg.int.cold <- lm(log(AAM)~ColdTemp:Condition, data = sub)
  reg.group.cold <- lm(log(AAM)~ColdTemp*Condition, data = sub)
  
  # AICs for cold
  asian.linear.results[i,3]<-as.numeric(AICc(reg.linear.cold))
  asian.add.results[i,3]<-as.numeric(AICc(reg.add.cold))
  asian.int.results[i,3]<-as.numeric(AICc(reg.int.cold))
  asian.group.results[i,3]<-as.numeric(AICc(reg.group.cold))
  
  # R2 for cold
  asian.linear.results[i,4]<-summary(reg.linear.cold)$adj.r.squared
  asian.add.results[i,4]<-summary(reg.add.cold)$adj.r.squared
  asian.int.results[i,4]<-summary(reg.int.cold)$adj.r.squared
  asian.group.results[i,4]<-summary(reg.group.cold)$adj.r.squared
}


## R^2 values for the four models
# annual
r2annual <- data.frame(
  Model = c("Simple linear", "Linear additive", "Interaction", "Grouped"),
  R2 = c(mean(unique(asian.linear.results[,2])),
         mean(unique(asian.add.results[,2])),
         mean(unique(asian.int.results[,2])),
         mean(unique(asian.group.results[,2])))
)
kable(r2annual)

# cold
r2cold <- data.frame(
  Model = c("Simple linear", "Linear additive", "Interaction", "Grouped"),
  R2 = c(mean(unique(asian.linear.results[,4])),
         mean(unique(asian.add.results[,4])),
         mean(unique(asian.int.results[,4])),
         mean(unique(asian.group.results[,4])))
)
kable(r2cold)
```

### Check the slopes for all Asian carp models

```{r asian model summary}
summary(reg.linear.annual)
summary(reg.add.annual)
summary(reg.int.annual)
summary(reg.group.annual)
```

### Compare AICs for annual

```{r asian aic annual}
## Look at the distribution of the differences between AIC scores
# Calculate the differences of AIC values
aic.asian <- matrix(NA,1000,3) # store the differences in AIC values
aic.asian[,1] <- asian.add.results[,1] - asian.linear.results[,1]
aic.asian[,2] <- asian.int.results[,1] - asian.linear.results[,1]
aic.asian[,3] <- asian.group.results[,1] - asian.linear.results[,1]

# Create a data frame
data <- as.data.frame(aic.asian)
colnames(data) <- c("additive-linear","interation-linear","group-linear")

# Convert to long data format
data_long <- data %>%
  pivot_longer(cols = everything(), names_to = "Group", values_to = "Value")

# Define the desired order of groups
desired_order <- c("additive-linear","interation-linear","group-linear")

# Convert "Group" to a factor with desired order
data_long$Group <- factor(data_long$Group, levels = desired_order)

# Violin plot
ggplot(data_long, aes(x = Group, y = Value, fill = Group))+
  geom_violin()+
  labs(title = "Differences of AIC scores among models, using simple linear model as base. Annual Temp")+
  theme_bw()


## Check the AICc scores and akaike weights in 1000 iterations
weight.matrix <- matrix(NA, 1000, 4)
count <- numeric(0)

for (i in 1:1000) {
  # Create a list of the aic values of the current iteration
  aic_value <- c(asian.linear.results[i,1], asian.add.results[i,1],
               asian.int.results[i,1], asian.group.results[i,1])
  
  ## check the akaike weights
  weight <- compute_akaike_weights(aic_value)
  weight.matrix[i,c(1,2,3,4)] <- round(weight[c(1,2,3,4)],3)
  
  ## check the AICc scores
  indexing <- compare_aic_scores(aic_value)
  if (indexing != -999) {
    count <- c(count, indexing)
  }
}

summary(weight.matrix)
table(count)
```

* When looking at each iteration, we saw that around 35% of the times the simple linear model is the best.

* In general, the linear model had the smallest AIC values.


### Compare AICs for the cold

```{r asian aic cold}
# Calculate the differences of AIC values
aic.asian <- matrix(NA,1000,3) # store the differences in AIC values
aic.asian[,1] <- asian.add.results[,3] - asian.linear.results[,3]
aic.asian[,2] <- asian.int.results[,3] - asian.linear.results[,3]
aic.asian[,3] <- asian.group.results[,3] - asian.linear.results[,3]

# Look at the distribution of differences
# Create a data frame
data <- as.data.frame(aic.asian)
colnames(data) <- c("additive-linear","interation-linear","group-linear")

# Convert to long data format
data_long <- data %>%
  pivot_longer(cols = everything(), names_to = "Group", values_to = "Value")

# Define the desired order of groups
desired_order <- c("additive-linear","interation-linear","group-linear")

# Convert "Group" to a factor with desired order
data_long$Group <- factor(data_long$Group, levels = desired_order)

# Violin plot
ggplot(data_long, aes(x = Group, y = Value, fill = Group))+
  geom_violin()+
  labs(title = "Differences of AIC scores among models, using simple linear model as base. Cold Temp")+
  theme_bw()


## Check the AICc scores and akaike weights in 1000 iterations
weight.matrix <- matrix(NA, 1000, 4)
count <- numeric(0)

for (i in 1:1000) {
  # Create a list of the aic values of the current iteration
  aic_value <- c(asian.linear.results[i,3], asian.add.results[i,3],
               asian.int.results[i,3], asian.group.results[i,3])
  
  ## check the akaike weights
  weight <- compute_akaike_weights(aic_value)
  weight.matrix[i,c(1,2,3,4)] <- round(weight[c(1,2,3,4)],3)
  
  ## check the AICc scores
  indexing <- compare_aic_scores(aic_value)
  if (indexing != -999) {
    count <- c(count, indexing)
  }
}

summary(weight.matrix)
table(count)
```

* When looking at each iteration, we saw that around 28% of the times the simple linear model is the best.

* In general, the linear model had the smallest AIC values.


### Compare between annual and cold

```{r asian aic compare}
# Calculate the differences of AIC values
aic.asian <- matrix(NA,1000,4) # store the differences in AIC values
aic.asian[,1] <- asian.linear.results[,3] - asian.linear.results[,1]
aic.asian[,2] <- asian.add.results[,3] - asian.add.results[,1]
aic.asian[,3] <- asian.int.results[,3] - asian.int.results[,1]
aic.asian[,4] <- asian.group.results[,3] - asian.group.results[,1]

# Look at the distribution of differences
# Create a data frame
data <- as.data.frame(aic.asian)
colnames(data) <- c("linear","additive","interaction","grouped")

# Convert to long data format
data_long <- data %>%
  pivot_longer(cols = everything(), names_to = "Group", values_to = "Value")

# Define the desired order of groups
desired_order <- c("linear","additive","interaction","grouped")

# Convert "Group" to a factor with desired order
data_long$Group <- factor(data_long$Group, levels = desired_order)

# Violin plot
ggplot(data_long, aes(x = Group, y = Value, fill = Group))+
  geom_violin()+
  labs(title = "Differences of AIC scores among models, using AnnualTemp as base.")+
  theme_bw()


## Checking AIC values in each iteration
count <- NA

for (i in 1:1000) {
  # Create a list of the aic values of the current iteration
  aic_value <- c(asian.linear.results[i,1], asian.linear.results[i,3])
  smallest_aic <- min(aic_value)
  # Determining if the smallest value is 2 units smaller than the others
  is_smaller_by_two <- all(smallest_aic + 2 <= aic_value[aic_value != smallest_aic])
  
  # Append the index of the current list if smaller than 2 units
  if (is_smaller_by_two) {
    count <- c(count, which(aic_value == smallest_aic))
  }
}

count
length(count)-1
```

* With the simple linear model, around 16% of the time when using Annualtemp is preferred over using ColdTemp.



## Grass carp

### Define and models and check the R2

```{r grass carp model}
Grass.clean <- Grass %>% 
  filter(Condition %in% c("natural", "artificial"))

table(Grass.clean$Code)


## Subsampling for 1000 times (define all four models in one iteration!)
# Create the matrices to store the results
grass.linear.results <- matrix(NA,1000,4)
grass.add.results <- matrix(NA,1000,4)
grass.int.results <- matrix(NA,1000,4)
grass.group.results <- matrix(NA,1000,4)

# Iteration (put both annual and cold inside one iteration)
for(i in 1:1000){
  sub <- Grass.clean %>% group_by(Code) %>% sample_n(size=1)
  
  # annual
  reg.linear.annual <- lm(log(AAM)~AnnualTemp, data = sub)
  reg.add.annual <- lm(log(AAM)~AnnualTemp+Condition, data = sub)
  reg.int.annual <- lm(log(AAM)~AnnualTemp:Condition, data = sub)
  reg.group.annual <- lm(log(AAM)~AnnualTemp*Condition, data = sub)
  
  # AICs for annual
  grass.linear.results[i,1]<-as.numeric(AICc(reg.linear.annual))
  grass.add.results[i,1]<-as.numeric(AICc(reg.add.annual))
  grass.int.results[i,1]<-as.numeric(AICc(reg.int.annual))
  grass.group.results[i,1]<-as.numeric(AICc(reg.group.annual))
  
  # R2 for annual
  grass.linear.results[i,2]<-summary(reg.linear.annual)$adj.r.squared
  grass.add.results[i,2]<-summary(reg.add.annual)$adj.r.squared
  grass.int.results[i,2]<-summary(reg.int.annual)$adj.r.squared
  grass.group.results[i,2]<-summary(reg.group.annual)$adj.r.squared
  
  # cold
  reg.linear.cold <- lm(log(AAM)~ColdTemp, data = sub)
  reg.add.cold <- lm(log(AAM)~ColdTemp+Condition, data = sub)
  reg.int.cold <- lm(log(AAM)~ColdTemp:Condition, data = sub)
  reg.group.cold <- lm(log(AAM)~ColdTemp*Condition, data = sub)
  
  # AICs for cold
  grass.linear.results[i,3]<-as.numeric(AICc(reg.linear.cold))
  grass.add.results[i,3]<-as.numeric(AICc(reg.add.cold))
  grass.int.results[i,3]<-as.numeric(AICc(reg.int.cold))
  grass.group.results[i,3]<-as.numeric(AICc(reg.group.cold))
  
  # R2 for cold
  grass.linear.results[i,4]<-summary(reg.linear.cold)$adj.r.squared
  grass.add.results[i,4]<-summary(reg.add.cold)$adj.r.squared
  grass.int.results[i,4]<-summary(reg.int.cold)$adj.r.squared
  grass.group.results[i,4]<-summary(reg.group.cold)$adj.r.squared
}


## R^2 values for the four models
# annual
r2annual <- data.frame(
  Model = c("Simple linear", "Linear additive", "Interaction", "Grouped"),
  R2 = c(mean(unique(grass.linear.results[,2])),
         mean(unique(grass.add.results[,2])),
         mean(unique(grass.int.results[,2])),
         mean(unique(grass.group.results[,2])))
)
kable(r2annual)

# cold
r2cold <- data.frame(
  Model = c("Simple linear", "Linear additive", "Interaction", "Grouped"),
  R2 = c(mean(unique(grass.linear.results[,4])),
         mean(unique(grass.add.results[,4])),
         mean(unique(grass.int.results[,4])),
         mean(unique(grass.group.results[,4])))
)
kable(r2cold)
```

### Check the slopes for all Grass carp models

```{r grass model summary}
summary(reg.linear.annual)
summary(reg.add.annual)
summary(reg.int.annual)
summary(reg.group.annual)

summary(reg.linear.cold)
summary(reg.add.cold)
summary(reg.int.cold)
summary(reg.group.cold)
```

### Compare AICs for annual

```{r grass aic annual}
# Calculate the differences of AIC values
aic.grass <- matrix(NA,1000,3) # store the differences in AIC values
aic.grass[,1] <- grass.add.results[,1] - grass.linear.results[,1]
aic.grass[,2] <- grass.int.results[,1] - grass.linear.results[,1]
aic.grass[,3] <- grass.group.results[,1] - grass.linear.results[,1]

# Look at the distribution of differences
# Create a data frame
data <- as.data.frame(aic.grass)
colnames(data) <- c("additive-linear","interation-linear","group-linear")

# Convert to long data format
data_long <- data %>%
  pivot_longer(cols = everything(), names_to = "Group", values_to = "Value")

# Define the desired order of groups
desired_order <- c("additive-linear","interation-linear","group-linear")

# Convert "Group" to a factor with desired order
data_long$Group <- factor(data_long$Group, levels = desired_order)

# Violin plot
ggplot(data_long, aes(x = Group, y = Value, fill = Group))+
  geom_violin()+
  labs(title = "Differences of AIC scores among models, using simple linear model as base. Annual Temp")+
  theme_bw()


## Check the AICc scores and akaike weights in 1000 iterations
weight.matrix <- matrix(NA, 1000, 4)
count <- numeric(0)

for (i in 1:1000) {
  # Create a list of the aic values of the current iteration
  aic_value <- c(grass.linear.results[i,1], grass.add.results[i,1],
               grass.int.results[i,1], grass.group.results[i,1])
  
  ## check the akaike weights
  weight <- compute_akaike_weights(aic_value)
  weight.matrix[i,c(1,2,3,4)] <- round(weight[c(1,2,3,4)],3)
  
  ## check the AICc scores
  indexing <- compare_aic_scores(aic_value)
  if (indexing != -999) {
    count <- c(count, indexing)
  }
}

summary(weight.matrix)
table(count)
```

* For grass carp, AIC for simple linear model was always smaller than the additive and interaction model, but within two units, and significantly smaller than the grouped-specific model (greater than 2 units).

* 68% of the times when the simple linear model perfroms better.


### Compare AICs for the cold

```{r grass aic cold}
# Calculate the differences of AIC values
aic.grass <- matrix(NA,1000,3) # store the differences in AIC values
aic.grass[,1] <- grass.add.results[,3] - grass.linear.results[,3]
aic.grass[,2] <- grass.int.results[,3] - grass.linear.results[,3]
aic.grass[,3] <- grass.group.results[,3] - grass.linear.results[,3]

# Look at the distribution of differences
# Create a data frame
data <- as.data.frame(aic.grass)
colnames(data) <- c("additive-linear","interation-linear","group-linear")

# Convert to long data format
data_long <- data %>%
  pivot_longer(cols = everything(), names_to = "Group", values_to = "Value")

# Define the desired order of groups
desired_order <- c("additive-linear","interation-linear","group-linear")

# Convert "Group" to a factor with desired order
data_long$Group <- factor(data_long$Group, levels = desired_order)

# Violin plot
ggplot(data_long, aes(x = Group, y = Value, fill = Group))+
  geom_violin()+
  labs(title = "Differences of AIC scores among models, using simple linear model as base. Cold Temp")+
  theme_bw()


## Check the AICc scores and akaike weights in 1000 iterations
weight.matrix <- matrix(NA, 1000, 4)
count <- numeric(0)

for (i in 1:1000) {
  # Create a list of the aic values of the current iteration
  aic_value <- c(grass.linear.results[i,3], grass.add.results[i,3],
               grass.int.results[i,3], grass.group.results[i,3])
  
  ## check the akaike weights
  weight <- compute_akaike_weights(aic_value)
  weight.matrix[i,c(1,2,3,4)] <- round(weight[c(1,2,3,4)],3)
  
  ## check the AICc scores
  indexing <- compare_aic_scores(aic_value)
  if (indexing != -999) {
    count <- c(count, indexing)
  }
}

summary(weight.matrix)
table(count)
```

* Same conclusion as AnnualTemp. 100% of the times when the simple model performs better.


### Compare between annual and cold

```{r grass aic compare}
# Calculate the differences of AIC values
aic.grass <- matrix(NA,1000,4) # store the differences in AIC values
aic.grass[,1] <- grass.linear.results[,3] - grass.linear.results[,1]
aic.grass[,2] <- grass.add.results[,3] - grass.add.results[,1]
aic.grass[,3] <- grass.int.results[,3] - grass.int.results[,1]
aic.grass[,4] <- grass.group.results[,3] - grass.group.results[,1]

# Look at the distribution of differences
# Create a data frame
data <- as.data.frame(aic.grass)
colnames(data) <- c("linear","additive","interaction","grouped")

# Convert to long data format
data_long <- data %>%
  pivot_longer(cols = everything(), names_to = "Group", values_to = "Value")

# Define the desired order of groups
desired_order <- c("linear","additive","interaction","grouped")

# Convert "Group" to a factor with desired order
data_long$Group <- factor(data_long$Group, levels = desired_order)

# Violin plot
ggplot(data_long, aes(x = Group, y = Value, fill = Group))+
  geom_violin()+
  labs(title = "Differences of AIC scores among models, using AnnualTemp as base.")+
  theme_bw()


## Checking AIC values in each iteration
count <- NA

for (i in 1:1000) {
  # Create a list of the aic values of the current iteration
  aic_value <- c(grass.linear.results[i,1], grass.linear.results[i,3])
  smallest_aic <- min(aic_value)
  # Determining if the smallest value is 2 units smaller than the others
  is_smaller_by_two <- all(smallest_aic + 2 <= aic_value[aic_value != smallest_aic])
  
  # Append the index of the current list if smaller than 2 units
  if (is_smaller_by_two) {
    count <- c(count, which(aic_value == smallest_aic))
  }
}
count
summary(count)
```

* Cold temperature did not show any preference over Annual temperature. No significant differences.


## Bighead and silver carp

### Define the models and compare the R2

```{r bighead silver carp model}
Big.sil.clean <- Big.sil %>% 
  filter(Condition %in% c("natural", "artificial"))

table(Big.sil.clean$Code)


## Subsampling for 1000 times (define all four models in one iteration!)
# Create the matrices to store the results
bs.linear.results <- matrix(NA,1000,4)
bs.add.results <- matrix(NA,1000,4)
bs.int.results <- matrix(NA,1000,4)
bs.group.results <- matrix(NA,1000,4)

# Iteration (put both annual and cold inside one iteration)
for(i in 1:1000){
  sub <- Big.sil.clean %>% group_by(Code) %>% sample_n(size=1)
  
  # annual
  reg.linear.annual <- lm(log(AAM)~AnnualTemp, data = sub)
  reg.add.annual <- lm(log(AAM)~AnnualTemp+Condition, data = sub)
  reg.int.annual <- lm(log(AAM)~AnnualTemp:Condition, data = sub)
  reg.group.annual <- lm(log(AAM)~AnnualTemp*Condition, data = sub)
  
  # AICs for annual
  bs.linear.results[i,1]<-as.numeric(AICc(reg.linear.annual))
  bs.add.results[i,1]<-as.numeric(AICc(reg.add.annual))
  bs.int.results[i,1]<-as.numeric(AICc(reg.int.annual))
  bs.group.results[i,1]<-as.numeric(AICc(reg.group.annual))
  
  # R2 for annual
  bs.linear.results[i,2]<-summary(reg.linear.annual)$adj.r.squared
  bs.add.results[i,2]<-summary(reg.add.annual)$adj.r.squared
  bs.int.results[i,2]<-summary(reg.int.annual)$adj.r.squared
  bs.group.results[i,2]<-summary(reg.group.annual)$adj.r.squared
  
  # cold
  reg.linear.cold <- lm(log(AAM)~ColdTemp, data = sub)
  reg.add.cold <- lm(log(AAM)~ColdTemp+Condition, data = sub)
  reg.int.cold <- lm(log(AAM)~ColdTemp:Condition, data = sub)
  reg.group.cold <- lm(log(AAM)~ColdTemp*Condition, data = sub)
  
  # AICs for cold
  bs.linear.results[i,3]<-as.numeric(AICc(reg.linear.cold))
  bs.add.results[i,3]<-as.numeric(AICc(reg.add.cold))
  bs.int.results[i,3]<-as.numeric(AICc(reg.int.cold))
  bs.group.results[i,3]<-as.numeric(AICc(reg.group.cold))
  
  # R2 for cold
  bs.linear.results[i,4]<-summary(reg.linear.cold)$adj.r.squared
  bs.add.results[i,4]<-summary(reg.add.cold)$adj.r.squared
  bs.int.results[i,4]<-summary(reg.int.cold)$adj.r.squared
  bs.group.results[i,4]<-summary(reg.group.cold)$adj.r.squared
}


## R^2 values for the four models
# annual
r2annual <- data.frame(
  Model = c("Simple linear", "Linear additive", "Interaction", "Grouped"),
  R2 = c(mean(unique(bs.linear.results[,2])),
         mean(unique(bs.add.results[,2])),
         mean(unique(bs.int.results[,2])),
         mean(unique(bs.group.results[,2])))
)
kable(r2annual)

# cold
r2cold <- data.frame(
  Model = c("Simple linear", "Linear additive", "Interaction", "Grouped"),
  R2 = c(mean(unique(bs.linear.results[,4])),
         mean(unique(bs.add.results[,4])),
         mean(unique(bs.int.results[,4])),
         mean(unique(bs.group.results[,4])))
)
kable(r2cold)
```

### Check the slopes for all bighead and silver carp models

```{r bs model summary}
summary(reg.linear.annual)
summary(reg.add.annual)
summary(reg.int.annual)
summary(reg.group.annual)

summary(reg.linear.cold)
summary(reg.add.cold)
summary(reg.int.cold)
summary(reg.group.cold)
```

### Compare AICs for annual

```{r bs aic annual}
# Calculate the differences of AIC values
aic.bs <- matrix(NA,1000,3) # store the differences in AIC values
aic.bs[,1] <- bs.add.results[,1] - bs.linear.results[,1]
aic.bs[,2] <- bs.int.results[,1] - bs.linear.results[,1]
aic.bs[,3] <- bs.group.results[,1] - bs.linear.results[,1]

# Look at the distribution of differences
# Create a data frame
data <- as.data.frame(aic.bs)
colnames(data) <- c("additive-linear","interation-linear","group-linear")

# Convert to long data format
data_long <- data %>%
  pivot_longer(cols = everything(), names_to = "Group", values_to = "Value")

# Define the desired order of groups
desired_order <- c("additive-linear","interation-linear","group-linear")

# Convert "Group" to a factor with desired order
data_long$Group <- factor(data_long$Group, levels = desired_order)

# Violin plot
ggplot(data_long, aes(x = Group, y = Value, fill = Group))+
  geom_violin()+
  labs(title = "Differences of AIC scores among models, using simple linear model as base. Annual Temp")+
  theme_bw()


## Check the AICc scores and akaike weights in 1000 iterations
weight.matrix <- matrix(NA, 1000, 4)
count <- numeric(0)

for (i in 1:1000) {
  # Create a list of the aic values of the current iteration
  aic_value <- c(bs.linear.results[i,1], bs.add.results[i,1],
               bs.int.results[i,1], bs.group.results[i,1])
  
  ## check the akaike weights
  weight <- compute_akaike_weights(aic_value)
  weight.matrix[i,c(1,2,3,4)] <- round(weight[c(1,2,3,4)],3)
  
  ## check the AICc scores
  indexing <- compare_aic_scores(aic_value)
  if (indexing != -999) {
    count <- c(count, indexing)
  }
}

summary(weight.matrix)
table(count)
```

* We saw a large range in the difference of AIC values due to a larger number of combinations for subsampling sets.

* 5.8% times simple model. 22% times linear additive model.


### Compare AICs for the cold

```{r bs aic cold}
# Calculate the differences of AIC values
aic.bs <- matrix(NA,1000,3) # store the differences in AIC values
aic.bs[,1] <- bs.add.results[,3] - bs.linear.results[,3]
aic.bs[,2] <- bs.int.results[,3] - bs.linear.results[,3]
aic.bs[,3] <- bs.group.results[,3] - bs.linear.results[,3]

# Look at the distribution of differences
# Create a data frame
data <- as.data.frame(aic.bs)
colnames(data) <- c("additive-linear","interation-linear","group-linear")

# Convert to long data format
data_long <- data %>%
  pivot_longer(cols = everything(), names_to = "Group", values_to = "Value")

# Define the desired order of groups
desired_order <- c("additive-linear","interation-linear","group-linear")

# Convert "Group" to a factor with desired order
data_long$Group <- factor(data_long$Group, levels = desired_order)

# Violin plot
ggplot(data_long, aes(x = Group, y = Value, fill = Group))+
  geom_violin()+
  labs(title = "Differences of AIC scores among models, using simple linear model as base. Cold Temp")+
  theme_bw()


## Check the AICc scores and akaike weights in 1000 iterations
weight.matrix <- matrix(NA, 1000, 4)
count <- numeric(0)

for (i in 1:1000) {
  # Create a list of the aic values of the current iteration
  aic_value <- c(bs.linear.results[i,3], bs.add.results[i,3],
               bs.int.results[i,3], bs.group.results[i,3])
  
  ## check the akaike weights
  weight <- compute_akaike_weights(aic_value)
  weight.matrix[i,c(1,2,3,4)] <- round(weight[c(1,2,3,4)],3)
  
  ## check the AICc scores
  indexing <- compare_aic_scores(aic_value)
  if (indexing != -999) {
    count <- c(count, indexing)
  }
}

summary(weight.matrix)
table(count)
```

* 47% simple linear model, 6.6% linear additive model.


### Compare between annual and cold

```{r bs aic compare}
# Calculate the differences of AIC values
aic.bs <- matrix(NA,1000,4) # store the differences in AIC values
aic.bs[,1] <- bs.linear.results[,3] - bs.linear.results[,1]
aic.bs[,2] <- bs.add.results[,3] - bs.add.results[,1]
aic.bs[,3] <- bs.int.results[,3] - bs.int.results[,1]
aic.bs[,4] <- bs.group.results[,3] - bs.group.results[,1]

# Look at the distribution of differences
# Create a data frame
data <- as.data.frame(aic.bs)
colnames(data) <- c("linear","additive","interaction","grouped")

# Convert to long data format
data_long <- data %>%
  pivot_longer(cols = everything(), names_to = "Group", values_to = "Value")

# Define the desired order of groups
desired_order <- c("linear","additive","interaction","grouped")

# Convert "Group" to a factor with desired order
data_long$Group <- factor(data_long$Group, levels = desired_order)

# Violin plot
ggplot(data_long, aes(x = Group, y = Value, fill = Group))+
  geom_violin()+
  labs(title = "Differences of AIC scores among models, using AnnualTemp as base.")+
  theme_bw()


## Checking AIC values in each iteration
count <- NA

for (i in 1:1000) {
  # Create a list of the aic values of the current iteration
  aic_value <- c(bs.linear.results[i,1], bs.linear.results[i,3])
  smallest_aic <- min(aic_value)
  # Determining if the smallest value is 2 units smaller than the others
  is_smaller_by_two <- all(smallest_aic + 2 <= aic_value[aic_value != smallest_aic])
  
  # Append the index of the current list if smaller than 2 units
  if (is_smaller_by_two) {
    count <- c(count, which(aic_value == smallest_aic))
  }
}

count
table(count)
```

* For bs, using annual temperature is always better than using the cold temperature (difference in AIC > 2) for all models. This was also explained by lower R^2 values for the cold temperature models.

* For bighead and silver carp, there were fewer data points (32 datapoints in total), but more subsample sets (10 sets of subsamples. This gave us 19 data points after subsampling with a much larger variation (due to a larger number of combinations).

* At extremes, we would have 13 artificial and 6 natural (if all subseting choose artificial); or 10 natural and 9 artificial (if all subsetting choose natural).



## Concluding points

1.  Black carp: using cold temperature have a better fit (higher R2). No preference over the four types of models.

2.  Black carp: When separate the two conditions, we see a large increase in the R2 for the natural condition. The artificial condition alone did not have a significant relationship between log AAM and temperature.

3.  Aisan carp: No preference over the four models.
